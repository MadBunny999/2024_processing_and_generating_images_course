{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка и генерация изображений\n",
    "## Лекция №6. Метрики оценки моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Постановка задачи генерации\n",
    "\n",
    "*****\n",
    "\n",
    "<b>Дано:</b>\n",
    "- Набор независимых одинаково распределенных случайных величин $\\{X_i\\}_{i=1}^{n} \\in \\mathcal{X}$  (напр, $\\mathcal{X} \\in \\mathcal{R}^m$) из неизвестного распределения $\\pi(x)$.\\\n",
    "- Выборка $\\{x_i\\}_{i=1}^{n}$, где $x_i$ - реализация случайной величины.\n",
    "\n",
    "<b>Задача:</b> \n",
    "1. Оценить $\\pi(x)$ по выборке\n",
    "2. Генерировать новые элементы $x$ из $\\pi(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Генеративные модели\n",
    "\n",
    "*****\n",
    "\n",
    "<div>\n",
    "    <img src=./imgs/generetive_models_zoo.drawio.png style=width:800px>\n",
    "</div>\n",
    "\n",
    "[Исаченко Р. Порождающие модели машинного обучения. МФТИ, 2023](https://www.youtube.com/playlist?list=PLk4h7dmY2eYHVCEMMMqdKes__ehs5mRtR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подключение библиотек\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image \n",
    "import torchvision.transforms as transforms\n",
    "from diffusers import KandinskyV22Pipeline, KandinskyV22PriorPipeline\n",
    "\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# контроль памяти GPU\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразование промптов в эмбеддинги\n",
    "\n",
    "pipe_prior = KandinskyV22PriorPipeline.from_pretrained(\"kandinsky-community/kandinsky-2-2-prior\").to(\"cuda\")\n",
    "\n",
    "prompts = [\"red cat\",\n",
    "           \"surfer catches a wave\",\n",
    "           \"the police detain the criminal\",\n",
    "           \"Trump won the election\",\n",
    "           \"a ufo has arrived on earth\",\n",
    "           \"LA seaside party\",\n",
    "           \"molten wall clock\"]\n",
    "\n",
    "image_embs, negative_image_embs = pipe_prior(prompts).to_tuple()\n",
    "\n",
    "del pipe_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерация изображений по эмбеддингам промптов\n",
    "\n",
    "pipe = KandinskyV22Pipeline.from_pretrained(\"kandinsky-community/kandinsky-2-2-decoder\").to(\"cuda\")\n",
    "\n",
    "for index, (image_emb, negative_image_emb) in enumerate(zip(image_embs, negative_image_embs)):\n",
    "    image = pipe(\n",
    "        image_embeds=image_emb.reshape(1, -1),\n",
    "        negative_image_embeds=negative_image_emb.reshape(1, -1),\n",
    "        height=512,\n",
    "        width=512,\n",
    "        num_inference_steps=50,\n",
    "    ).images\n",
    "    image[0].save(f\"{index + 1}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение сгенерированных и реальных изображений и преобразование в тензоры\n",
    "\n",
    "path_gen = './imgs/generated'\n",
    "path_orig = './imgs/original'\n",
    "\n",
    "gen_file_paths = [path_gen + '/' + file_name for file_name in os.listdir(path_gen)]\n",
    "orig_file_paths = [path_orig + '/' + file_name for file_name in os.listdir(path_orig)]\n",
    "\n",
    "gen_tensors = torch.zeros((7, 3, 512, 512))\n",
    "orig_tensors = torch.zeros((7, 3, 512, 512))\n",
    "\n",
    "pil_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.PILToTensor()\n",
    "    ])\n",
    "\n",
    "for index, (orig_file_path, gen_file_path) in enumerate(zip(orig_file_paths, gen_file_paths)):\n",
    "    gen_im = Image.open(gen_file_path)\n",
    "    orig_im = Image.open(orig_file_path)\n",
    "    gen_tensor = pil_transform(gen_im) / 256\n",
    "    orig_tensor = pil_transform(orig_im) / 256\n",
    "\n",
    "    gen_tensors[index] = gen_tensor\n",
    "    orig_tensors[index] = orig_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Классификация метрик\n",
    "\n",
    "*****\n",
    "\n",
    "Метрики оценки генеративных моделей:\n",
    "+ Основанных на правдоподобии (likelihood-based):\n",
    "    - Правдоподобие\n",
    "+ Неявной плотности (likelihood-free):\n",
    "    - IS (Inception score)\n",
    "    - FID (Frechet Inception Distance)\n",
    "    - Precision-Recall\n",
    "\n",
    "Метрики оценки качества изображений:\n",
    "- Low-level\n",
    "    - PixCorr (Pixelwise Correlation)\n",
    "    - SSIM (Structural Similarity Index Measure)\n",
    "- High-level\n",
    "    - CLIP (Contrastive Language-Image Pre-Training)\n",
    "    - SwAV (Swapping Assignments between multiple Views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Метрики оценки генеративных моделей\n",
    "\n",
    "*****\n",
    "\n",
    "Представим, что у нас есть предобученный классификатор (оракул), который выдает на выходе распределение классов $p(y|x)$.\\\n",
    "Мы хотим, чтобы изображения генеративной модели удовлетворяли двум критериям:\n",
    "<ol>\n",
    "    <li>Sharpness\n",
    "        <div><img src=./imgs/sharpness.png style=width:800px> </div>\n",
    "        \n",
    "Каждый класс должен быть точно идентифицирован.\\\n",
    "Условное распределениен $p(y|x)$ должно иметь низкую энтропию.\n",
    "\n",
    "<li>Diversity\n",
    "    <div><img src=./imgs/diversity.png style=width:800px> </div>\n",
    "\n",
    "Хотим, чтобы семплы были разнообразные, то есть мы могли генерировать семплы разных классов с равной вероятностью. \\\n",
    "Маргинальное распределение $p(y) = \\int p(y|x) p(x) dx$ должно иметь высокую энтропию.\n",
    "</ol>\n",
    "\n",
    "[Stefano Ermon. Deep Generative Models. Stanford](https://deepgenerativemodels.github.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><img src=./imgs/sharpness_diversity.webp style=width:800px> </div>\n",
    "\n",
    "[David Mack. A simple explanation of the Inception Score. Medium](https://medium.com/octavian-ai/a-simple-explanation-of-the-inception-score-372dff6a8c7a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Inception Score\n",
    "- Sharpness:\n",
    "$$low \\ H(y|x) = - \\sum_{y} \\int_x p(y, x) log(p|x) dx$$\n",
    "- Diversity:\n",
    "$$high \\ H(y) = - \\sum_{y} p(y) log(p(y))$$\n",
    "- Inception Score:\n",
    "\\begin{split} \n",
    "IS & = exp(H(y) - H(y|x)) \\\\\n",
    "   & = exp \\left( - \\sum_{y} p(y) log(p(y)) + \\sum_{y} \\int_x p(y, x) log(p|x) dx\\right) \\\\\n",
    "   & = exp \\left( \\sum_{y} \\int_x  p(y, x) log\\frac{p(y|x)}{p(y)} dx\\right) \\\\\n",
    "   & = exp \\left( E_{x} \\sum_{y}  p(y | x) log\\frac{p(y|x)}{p(y)} \\right) \\\\\n",
    "   & = exp \\left(  E_{x} KL(p(y|x) || p(y)) \\right)\n",
    "\\end{split}\n",
    "- Недостатки:\n",
    "   - Если генеративная модель генерирует изображения с метками классов, отличных от меток классов классификатора (оракул), то IS будет низким.\n",
    "   - Если генеративная модель генерирует по одному изображению на класс, IS будел высоким (не измеряется внутриклассовое разнообразие).\n",
    "   \n",
    "[Salimans T. Improved Techniques for Training GANs, 2016](https://arxiv.org/abs/1606.03498)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kshch\\Projects\\Обработка и генерация изображений\\.venv\\Lib\\site-packages\\ignite\\handlers\\checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS on original data: 1.317\n",
      "IS on generated data: 1.531\n"
     ]
    }
   ],
   "source": [
    "# подсчет метрик\n",
    "from ignite.metrics import InceptionScore\n",
    "from ignite.handlers import Engine\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "tensors = {'original': orig_tensors, \n",
    "           'generated': gen_tensors}\n",
    "\n",
    "for key in tensors.keys():\n",
    "    metric = InceptionScore()\n",
    "    metric.attach(default_evaluator, \"is\")\n",
    "\n",
    "    state = default_evaluator.run([tensors[key]])\n",
    "    print(f'IS on {key} data:', round(state.metrics[\"is\"], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kshch\\Projects\\Обработка и генерация изображений\\.venv\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS on original data: (tensor(1.), tensor(0.))\n",
      "IS on generated data: (tensor(1.), tensor(2.4333e-08))\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.image.inception import InceptionScore\n",
    "\n",
    "inception = InceptionScore(normalize=True)\n",
    "inception.update((tensors['original']).to('cpu'))\n",
    "print('IS on original data:', inception.compute())\n",
    "\n",
    "inception = InceptionScore(normalize=True)\n",
    "inception.update((tensors['generated']).to('cpu'))\n",
    "print('IS on generated data:', inception.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Frechet Inception Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Определение:</b> \\\n",
    "Производящая функция моментов случайной величины $\\xi(t)$: $$M_{\\xi}(t) = E e^{\\xi t}$$\n",
    "\n",
    "<b>Теорема:</b> \\\n",
    "Если $\\pi(x)$ и $p(x|\\theta)$ имеют производящие функции моментов тогда:\n",
    "$$\\pi(x) = p(x|\\theta) \\Leftrightarrow E_{\\pi} x^k = E_{p} x^k \\ \\ \\ \\forall k \\geq 1$$\n",
    "\n",
    "\n",
    "<b>Frechet Inception Distance</b>\n",
    "$$ FID(\\pi, p) = ||m_{\\pi} - m_p||_2^2 + Tr \\left( \\sum_\\pi + \\sum_p - 2 \\sqrt{\\sum_\\pi \\sum_p} \\right)$$\n",
    "\n",
    "<div><img src=./imgs/FIDvsIS.png style=width:800px> </div>\n",
    "\n",
    "Недостатки:\n",
    "- Требуется большой датасет\n",
    "- Долгий процесс подсчета метрики\n",
    "- Оценка только 2х моментов\n",
    "\n",
    "[Heusel M. GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. 2017](https://arxiv.org/abs/1706.08500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.676093101501465\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "metric = FrechetInceptionDistance(feature=64, normalize=True)\n",
    "metric.update((tensors['original']).to('cpu'), real=True)\n",
    "metric.update((tensors['generated']).to('cpu'), real=False)\n",
    "fid = metric.compute().item()\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Precision-Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Идеи:</b>\n",
    "1. Sharpness: высокая точность изображений\n",
    "2. Diversity: высокая вариативность изображений\n",
    "\n",
    "<div><img src=./imgs/precision_recall.png style=width:800px> </div>\n",
    "\n",
    "<b>Проблема:</b> как определять, попала ли точка в распределение или нет (определение границ распределения)\\\n",
    "\n",
    "<b>Решение:</b>\\\n",
    "$S_{\\pi} = \\{x_i\\}_i^n \\sim \\pi(x)$ - real samples\\\n",
    "$S_{p} = \\{x_i\\}_i^n \\sim p(x)$ - generated samples\n",
    "\n",
    "Множества эмбеддингов: \\\n",
    "$G_\\pi = \\{g_i\\}_{i=1}^n$\\\n",
    "$G_p = \\{g_i\\}_{i=1}^n$\n",
    "\n",
    "Определим бинарную функцию:\n",
    "$$\n",
    "f(g, G)=\n",
    "    \\begin{cases}\n",
    "        1 & \\text{if } \\exists g' \\in G: ||g - g'||_2 \\leq ||g' - NN_k(g', G)||_2\\\\\n",
    "        0 & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "$$\n",
    "<div><img src=./imgs/distrib_approx.png style=width:800px> </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall:\n",
    "\n",
    "$PREC(G_\\pi, G_p) = \\frac{1}{n} \\sum_{g \\in G_p} f(g, G_\\pi)$ \n",
    "\n",
    "$REC(G_\\pi, G_p) = \\frac{1}{n} \\sum_{g \\in G_\\pi} f(g, G_p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><img src=./imgs/prec_rec_comparising.png style=width:800px> </div>\n",
    "\n",
    "[Kynkäänniemi T. Improved Precision and Recall Metric for Assessing Generative Models. 2019](https://arxiv.org/abs/1904.06991)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Truncation Trick</b>\n",
    "\n",
    "1. BigGAN: truncated normal sampling\\\n",
    "    $z \\sim N(0, 1)$\\\n",
    "    $x = G(z)$\\\n",
    "    $p(z|\\psi) = N(z | 0, 1) / \\int_{-\\infty}^{\\psi} N(z |0, 1) dz$\n",
    "\n",
    "<div style=display: flex; justify-content: center;>\n",
    "    <img src=./imgs/truncation_trick.jpg style=width:500px> \n",
    "    <img src=./imgs/truncation_trick_threshold.png style=width:700px> \n",
    "</div>\n",
    "\n",
    "2. StyleGAN \\\n",
    "$z' = \\hat{z} + \\psi \\cdot (z - \\hat{z}), \\ \\ \\hat{z} = E_z z$\n",
    "\n",
    "<div style=display: flex; justify-content: center;>\n",
    "    <img src=./imgs/truncation_trick2.jpg style=width:500px> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kynkaat/improved-precision-and-recall-metric?tab=readme-ov-file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Метрики оценки качества изображений\n",
    "\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Pixelwise Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r_{XY} = \\frac{cov_{XY}}{\\sigma_X \\sigma_Y} = \\frac{\\sum(X - \\overline{X})(Y - \\overline{Y})}{\\sqrt{\\sum(X - \\overline{X})^2 \\sum(Y - \\overline{Y})^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 541875])\n",
      "torch.Size([7, 541875])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 167.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20993910889691952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(425, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "])\n",
    "\n",
    "# Flatten images while keeping the batch dimension\n",
    "all_images_flattened = preprocess(orig_tensors).reshape(len(orig_tensors), -1).cpu()\n",
    "all_brain_recons_flattened = preprocess(gen_tensors).view(len(gen_tensors), -1).cpu()\n",
    "\n",
    "print(all_images_flattened.shape)\n",
    "print(all_brain_recons_flattened.shape)\n",
    "\n",
    "corrsum = 0\n",
    "for i in tqdm(range(7)):\n",
    "    corrsum += np.corrcoef(all_images_flattened[i], all_brain_recons_flattened[i])[0][1]\n",
    "corrmean = corrsum / 7\n",
    "\n",
    "pixcorr = corrmean\n",
    "print(pixcorr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Structural Similarity Index Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Идея:</b> движение скользящего окна по изображению с подсчетом метрики. Каждое окно разбивается на три компоненты: яркость, контраст и структура.\\\n",
    "<b>Замечание:</b> три компоненты независимы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Оценка яркости:\n",
    "$$\\mu_x = \\frac{1}{N} \\sum_{i=1}^N x_i$$\n",
    "\n",
    "2. Оценка контраста (несмещенная оценка):\n",
    "$$\\sigma_x = \\left( \\frac{1}{N - 1} \\sum_{i=1}^N (x_i - \\mu_x)^2 \\right) ^\\frac{1}{2}$$\n",
    "\n",
    "3. Нормализация:\n",
    "$$ \\frac{x - \\mu_x}{\\sigma_x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Введем функции:\n",
    "- $l(x, y)$ - функция сравнения яркостей $\\mu_x$ и $\\mu_y$\n",
    "- $c(x, y)$ - функция сравнения констанста $\\sigma_x$ и $\\sigma_y$\n",
    "- $s(x, y)$ - функция сравнения структур сигналов\n",
    "\n",
    "  Определим функцию:\n",
    "  $$S(x, y) = f(l(x, y), c(x, y), s(x, y))$$\n",
    "  которая должна удовлетворять следующим критериям:\n",
    "  - Симметричность: $S(x, y) = S(y, x)$\n",
    "  - Ограниченность: $S(x, y) <= 1$\n",
    "  - Единственность максимума:\\\n",
    "  $S(x, y) = 1 \\Leftrightarrow x = y$ (в дискретном случае, $x_i = y_i$, $i=1, 2, ..N$) \n",
    "\n",
    "\n",
    "\n",
    "2. Определим функции:\n",
    "  - Функция сравнения яркостей:\n",
    "  $$l(x, y) = \\frac{2 \\mu_x \\mu_y + c_1}{\\mu_x^2 + \\mu_y^2 + c_1} \\ \\ \\text{где} \\ \\ c_1 = (K_1 L)^2$$\n",
    "\n",
    "  - Функция сравнения контраста:\n",
    "  $$c(x, y) = \\frac{2 \\sigma_x \\sigma_y + c_2}{\\sigma_x^2 + \\sigma_y^2 + c_2}  \\ \\ \\text{где} \\ \\ c_2 = (K_2 L)^2$$\n",
    "\n",
    "  - Функция сравнения структуры:\n",
    "  $$s(x, y) = \\frac{\\sigma_{xy} + c_3}{\\sigma_x \\sigma_y + c_3}  \\ \\ \\text{где} \\ \\ c_3 = (K_3 L)^2$$\n",
    "  \n",
    "  * $\\sigma_{xy} = \\frac{1}{N - 1}\\sum_{i=1}^N(x_i - \\mu_x)(y_i - \\mu_y)$\n",
    "  * $L$ - динамический диапазон значений пикселей (255 для 8-битных изображений в оттенках серого)\n",
    "  * $K_{1, 2, 3} << 1$ - малая константа\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Комбинируем и доопределяем:\n",
    "  $$SSIM(x, y) = [l(x, y)]^\\alpha \\cdot [c(x, y)]^\\beta \\cdot [s(x, y)]^\\gamma \\ \\  \\text{где} \\ \\ \\alpha > 0, \\ \\beta > 0, \\ \\gamma > 0$$\n",
    "  \n",
    "  Определим:\n",
    "  - $\\alpha = \\beta = \\gamma = 1$\n",
    "  - $c_3 = c_2 / 2$\n",
    "\n",
    "  $$SSIM(x, y) = \\frac{(2 \\mu_x \\mu_y + c_1)(2 \\sigma_{xy} + c_2)}{(\\mu_x^2 + \\mu_y^2 + c_1)(\\sigma_x^2 + \\sigma_y^2 + c_2)}$$\n",
    "\n",
    "  <b>Замечание:</b> \n",
    "  - Функции $l(x, y)$, $c(x, y)$, $s(x, y)$, $SSIM(x, y)$ удовлетворяет критериям для $S(x,y)$\n",
    "  - Измеряется от -1(нет сходства) до 1(полное сходство). \n",
    "\n",
    "2. Усреднение по всем окнам\n",
    "  $$MSSIM(X, Y) = \\frac{1}{M} \\sum_{j=1}^M SSIM(x_j, y_j)$$\n",
    "  где\n",
    "  - X, Y - изображения\n",
    "  - $x_j, y_j$ - изображения в $j$-ом локальном окне"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div><img src='./imgs/mse_vs_ssim.png' style=width:600px> </div>\n",
    "\n",
    "\n",
    "[Zhou Wang. Image Quality Assessment: From Error Visibility to Structural Similarity. 2004](https://www.researchgate.net/publication/3327793_Image_Quality_Assessment_From_Error_Visibility_to_Structural_Similarity)\n",
    "\n",
    "Дополнительно:\n",
    "- [Universal Quality Image Index (UQI)](https://ieeexplore.ieee.org/document/995823)\n",
    "- [Complex Wavelet SSIM (CW-SSIM)](https://ieeexplore.ieee.org/document/5109651)\n",
    "- [Multi-scale Structural Similarity Index (MS-SSIM)](https://ieeexplore.ieee.org/abstract/document/1292216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2971)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "\n",
    "ssim = StructuralSimilarityIndexMeasure(data_range=1.0)\n",
    "ssim(tensors['generated'], tensors['original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 128.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3093117644560009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from skimage.color import rgb2gray\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(425, interpolation=transforms.InterpolationMode.BILINEAR), \n",
    "])\n",
    "\n",
    "img_gray = rgb2gray(preprocess(tensors['original']).permute((0,2,3,1)).cpu())\n",
    "recon_gray = rgb2gray(preprocess(tensors['generated']).permute((0,2,3,1)).cpu())\n",
    "\n",
    "ssim_score=[]\n",
    "for im,rec in tqdm(zip(img_gray,recon_gray), total=7):\n",
    "    ssim_score.append(ssim(rec, im, multichannel=True, gaussian_weights=True, sigma=1.5, use_sample_covariance=False, data_range=1.0))\n",
    "\n",
    "ssim = np.mean(ssim_score)\n",
    "print(ssim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Contrastive Language-Image Pre-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src='./imgs/clip.png' style=width:1000px>\n",
    "</div>\n",
    "\n",
    "[Radford A. Learning Transferable Visual Models From Natural Language Supervision. 2021](https://arxiv.org/pdf/2103.00020) \\\n",
    "[CLIP. GitHub](https://github.com/OpenAI/CLIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Swapping Assignments between multiple Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще метрики сравнения изображений:\n",
    "- Mean Squared Error (MSE) & Root Mean Squared Error (RMSE)\n",
    "- Peak Signal-to-Noise Ratio (PSNR)\n",
    "- Erreur Relative Globale Adimensionnelle de Synthèse (ERGAS)\n",
    "- Spatial Correlation Coefficient (SCC)\n",
    "- Relative Average Spectral Error (RASE)\n",
    "- Spectral Angle Mapper (SAM)\n",
    "- Visual Information Fidelity (VIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
